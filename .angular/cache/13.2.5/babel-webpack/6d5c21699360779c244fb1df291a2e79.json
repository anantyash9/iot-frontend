{"ast":null,"code":"import * as i0 from \"@angular/core\";\nimport * as i1 from \"../../services/io.service\";\nimport * as i2 from \"../../services/event.service\";\nexport let MicrophoneComponent = /*#__PURE__*/(() => {\n  class MicrophoneComponent {\n    constructor(ioService, eventService) {\n      this.ioService = ioService;\n      this.eventService = eventService;\n      let me = this;\n      me.startDisabled = false;\n      me.eventService.audioPlaying.subscribe(() => {\n        me.onStop();\n      });\n      me.eventService.resetInterface.subscribe(() => {\n        me.onStop(); // stop recording & waveform\n\n        me.eventService.audioStopping.emit(); // stop playing audio // reset the interface\n      });\n    }\n\n    ngOnInit() {\n      this.ioService.receiveStream('transcript', function (transcript) {\n        console.log(transcript);\n      });\n    }\n\n    onStart(speechContext) {\n      let me = this;\n      me.startDisabled = true; // make use of HTML 5/WebRTC, JavaScript getUserMedia()\n      // to capture the browser microphone stream\n\n      navigator.mediaDevices.getUserMedia({\n        audio: true\n      }).then(function (stream) {\n        me.recordAudio = RecordRTC(stream, {\n          type: 'audio',\n          mimeType: 'audio/webm',\n          sampleRate: 44100,\n          // MediaStreamRecorder, StereoAudioRecorder, WebAssemblyRecorder\n          // CanvasRecorder, GifRecorder, WhammyRecorder\n          recorderType: StereoAudioRecorder,\n          // Dialogflow / STT requires mono audio\n          numberOfAudioChannels: 1,\n          // get intervals based blobs\n          // value in milliseconds\n          // as you might not want to make detect calls every seconds\n          timeSlice: 14000,\n          // only for audio track\n          audioBitsPerSecond: 128000,\n          // used by StereoAudioRecorder\n          // the range 22050 to 96000.\n          // let us force 16khz recording:\n          desiredSampRate: 16000,\n\n          // as soon as the stream is available\n          ondataavailable(blob) {\n            if (!me.eventService.getIsPlaying()) {\n              me.ioService.sendBinaryStream(blob, speechContext);\n            }\n          }\n\n        });\n        me.recordAudio.startRecording(); // recording started\n      }).catch(function (error) {\n        console.error(error);\n      });\n    }\n\n    onStop() {\n      // recording stopped\n      this.startDisabled = false; // stop audio recorder\n\n      try {\n        this.recordAudio.stopRecording();\n      } catch (_a) {\n        console.log('recording already stopped');\n      }\n    }\n\n  }\n\n  MicrophoneComponent.ɵfac = function MicrophoneComponent_Factory(t) {\n    return new (t || MicrophoneComponent)(i0.ɵɵdirectiveInject(i1.IoService), i0.ɵɵdirectiveInject(i2.EventService));\n  };\n\n  MicrophoneComponent.ɵcmp = /*@__PURE__*/i0.ɵɵdefineComponent({\n    type: MicrophoneComponent,\n    selectors: [[\"app-microphone\"]],\n    decls: 0,\n    vars: 0,\n    template: function MicrophoneComponent_Template(rf, ctx) {},\n    styles: [\"\"]\n  });\n  return MicrophoneComponent;\n})();","map":null,"metadata":{},"sourceType":"module"}